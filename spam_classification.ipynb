{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Email Classification using Supervised Learning\n",
    "\n",
    "**IAI - Artificial Intelligence | Assignment 2 | 2025/2026**\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook implements a **spam email classification system** using supervised learning techniques. We compare four different algorithms on the UCI Spambase dataset:\n",
    "\n",
    "1. **CART** (Classification and Regression Trees) - Decision Tree with binary splits\n",
    "2. **k-Nearest Neighbors (k-NN)** - Instance-based learning\n",
    "3. **Random Forest** - Ensemble of Decision Trees\n",
    "4. **Oblique Decision Tree** - Linear combination splits (custom implementation)\n",
    "\n",
    "### Dataset: Spambase\n",
    "- **Source:** UCI Machine Learning Repository\n",
    "- **Instances:** 4,601 emails\n",
    "- **Features:** 57 continuous attributes\n",
    "- **Target:** Binary classification (1 = spam, 0 = ham)\n",
    "- **Class Distribution:** 39.4% spam, 60.6% ham\n",
    "\n",
    "### Notebook Structure\n",
    "- **Part 1:** Data Loading & Exploratory Data Analysis (EDA)\n",
    "- **Part 2:** Data Preprocessing\n",
    "- **Part 3:** Model Implementation & Training\n",
    "- **Part 4:** Evaluation & Comparison\n",
    "- **Part 5:** Advanced Analysis (Learning Curves, ROC Curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    StratifiedKFold,\n",
    "    learning_curve,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    auc\n",
    ")\n",
    "\n",
    "# Suppress warnings for clean output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ“ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 1: Data Loading & Exploratory Data Analysis\n",
    "\n",
    "### 1.1 Load the Spambase Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD DATASET - Option 1: Using UCI ML Repository API\n",
    "# ============================================================================\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Fetch dataset\n",
    "spambase = fetch_ucirepo(id=94) \n",
    "\n",
    "# Extract features and target\n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets.values.ravel()  # Convert to 1D array\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature names ({len(feature_names)}):\")\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ALTERNATIVE: Load from local CSV file (if API doesn't work)\n",
    "# ============================================================================\n",
    "\n",
    "# Uncomment the code below if you prefer to load from the .data file\n",
    "\n",
    "# # Define column names based on spambase.names\n",
    "# column_names = [\n",
    "#     'word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
    "#     'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet',\n",
    "#     'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will',\n",
    "#     'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
    "#     'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
    "#     'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money',\n",
    "#     'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650',\n",
    "#     'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857',\n",
    "#     'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology',\n",
    "#     'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    "#     'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project',\n",
    "#     'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
    "#     'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#',\n",
    "#     'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total',\n",
    "#     'spam'\n",
    "# ]\n",
    "\n",
    "# # Load data\n",
    "# df = pd.read_csv('spambase.data', header=None, names=column_names)\n",
    "# X = df.drop('spam', axis=1)\n",
    "# y = df['spam'].values\n",
    "# feature_names = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Basic Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET OVERVIEW\n",
    "# ============================================================================\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "df = X.copy()\n",
    "df['spam'] = y\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal samples: {len(df)}\")\n",
    "print(f\"Total features: {len(feature_names)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  - Ham (0):  {(y == 0).sum()} ({(y == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  - Spam (1): {(y == 1).sum()} ({(y == 1).mean()*100:.1f}%)\")\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary (first 10 features):\")\n",
    "df.iloc[:, :10].describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CLASS DISTRIBUTION\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#3B82F6', '#EF4444']\n",
    "labels = ['Ham (Not Spam)', 'Spam']\n",
    "sizes = [(y == 0).sum(), (y == 1).sum()]\n",
    "\n",
    "axes[0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90,\n",
    "            explode=(0, 0.05), shadow=True)\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "axes[1].bar(labels, sizes, color=colors, edgecolor='black', linewidth=1.2)\n",
    "axes[1].set_ylabel('Number of Samples', fontsize=12)\n",
    "axes[1].set_title('Class Counts', fontsize=14, fontweight='bold')\n",
    "for i, v in enumerate(sizes):\n",
    "    axes[1].text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOP DISCRIMINATIVE FEATURES (Spam vs Ham)\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate mean values for spam vs ham\n",
    "spam_means = df[df['spam'] == 1].drop('spam', axis=1).mean()\n",
    "ham_means = df[df['spam'] == 0].drop('spam', axis=1).mean()\n",
    "\n",
    "# Calculate difference ratio\n",
    "diff_ratio = (spam_means - ham_means) / (ham_means + 0.001)\n",
    "top_features = diff_ratio.abs().sort_values(ascending=False).head(15)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(top_features))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, ham_means[top_features.index], width, label='Ham', color='#3B82F6', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, spam_means[top_features.index], width, label='Spam', color='#EF4444', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.set_ylabel('Mean Value', fontsize=12)\n",
    "ax.set_title('Top 15 Discriminative Features: Spam vs Ham', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top_features.index, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE CORRELATION HEATMAP\n",
    "# ============================================================================\n",
    "\n",
    "# Select subset of features for readability\n",
    "selected_features = [\n",
    "    'word_freq_free', 'word_freq_money', 'word_freq_credit', 'word_freq_your',\n",
    "    'word_freq_you', 'word_freq_remove', 'word_freq_order', 'word_freq_mail',\n",
    "    'char_freq_!', 'char_freq_$', 'capital_run_length_average',\n",
    "    'capital_run_length_longest', 'capital_run_length_total'\n",
    "]\n",
    "\n",
    "# Check which features exist in our dataset\n",
    "existing_features = [f for f in selected_features if f in df.columns]\n",
    "existing_features.append('spam')\n",
    "\n",
    "corr_matrix = df[existing_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "            fmt='.2f', square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE DISTRIBUTIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Select key features to visualize\n",
    "key_features = ['word_freq_free', 'word_freq_money', 'char_freq_!', 'char_freq_$',\n",
    "                'capital_run_length_average', 'capital_run_length_total']\n",
    "\n",
    "# Filter to existing features\n",
    "key_features = [f for f in key_features if f in df.columns][:6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot distributions for spam and ham\n",
    "    df[df['spam'] == 0][feature].hist(ax=ax, bins=50, alpha=0.6, label='Ham', color='#3B82F6')\n",
    "    df[df['spam'] == 1][feature].hist(ax=ax, bins=50, alpha=0.6, label='Spam', color='#EF4444')\n",
    "    \n",
    "    ax.set_title(feature, fontsize=11, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.suptitle('Feature Distributions by Class', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 2: Data Preprocessing\n",
    "\n",
    "### 2.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "# Split data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train-Test Split:\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"  Test set:     {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(f\"  Ham:  {(y_train == 0).sum()} ({(y_train == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Spam: {(y_train == 1).sum()} ({(y_train == 1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Scaling\n",
    "\n",
    "Some algorithms (like k-NN) are sensitive to feature scales. We'll use StandardScaler to normalize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE SCALING\n",
    "# ============================================================================\n",
    "\n",
    "# StandardScaler for algorithms sensitive to scale (k-NN, Oblique Tree)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data, transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for convenience\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "\n",
    "print(\"Feature scaling applied (StandardScaler)\")\n",
    "print(f\"\\nScaled training data - Mean: {X_train_scaled.mean().mean():.6f}, Std: {X_train_scaled.std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 3: Model Implementation & Training\n",
    "\n",
    "### 3.1 Oblique Decision Tree Implementation\n",
    "\n",
    "Custom implementation using ISTA (Iterative Shrinkage-Thresholding Algorithm) for sparse linear splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OBLIQUE DECISION TREE - HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Numerically stable sigmoid function.\"\"\"\n",
    "    z = np.clip(z, -20, 20)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def soft_threshold(x, lambda_):\n",
    "    \"\"\"Proximal operator for L1 norm (soft thresholding).\"\"\"\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - lambda_, 0.0)\n",
    "\n",
    "def compute_loss_and_gradients(X, y, weights, bias):\n",
    "    \"\"\"Compute logistic loss and gradients.\"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    linear_scores = X @ weights + bias\n",
    "    probs = sigmoid(linear_scores)\n",
    "    \n",
    "    epsilon = 1e-12\n",
    "    probs_clipped = np.clip(probs, epsilon, 1 - epsilon)\n",
    "    loss = -np.sum(y * np.log(probs_clipped) + (1 - y) * np.log(1 - probs_clipped)) / n_samples\n",
    "    \n",
    "    error = (probs - y) / n_samples\n",
    "    grad_weights = X.T @ error\n",
    "    grad_bias = np.sum(error)\n",
    "    \n",
    "    return loss, grad_weights, grad_bias\n",
    "\n",
    "def train_logistic_ista(X, y, l1_lambda=0.01, max_iter=100, lr=0.1, tol=1e-5):\n",
    "    \"\"\"Train logistic regression with L1 penalty using ISTA.\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0.0\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        _, grad_w, grad_b = compute_loss_and_gradients(X, y, weights, bias)\n",
    "        \n",
    "        # Gradient step\n",
    "        weights_temp = weights - lr * grad_w\n",
    "        bias_new = bias - lr * grad_b\n",
    "        \n",
    "        # Proximal step (soft thresholding for L1)\n",
    "        weights_new = soft_threshold(weights_temp, lr * l1_lambda) if l1_lambda > 0 else weights_temp\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.linalg.norm(weights_new - weights) < tol and abs(bias_new - bias) < tol:\n",
    "            break\n",
    "        \n",
    "        weights, bias = weights_new, bias_new\n",
    "    \n",
    "    return weights, bias\n",
    "\n",
    "print(\"âœ“ Oblique Tree helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OBLIQUE DECISION TREE - NODE CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class ObliqueNode:\n",
    "    \"\"\"Node for Oblique Decision Tree.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.is_leaf = True\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.class_probs = None\n",
    "        self.predicted_class = None\n",
    "        self.n_samples = 0\n",
    "\n",
    "print(\"âœ“ ObliqueNode class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OBLIQUE DECISION TREE - MAIN CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class ObliqueDecisionTree(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Oblique Decision Tree with linear (non-axis-aligned) splits.\n",
    "    Uses L1 regularization for sparse, interpretable splits.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth=5, min_samples_split=10, min_samples_leaf=5,\n",
    "                 l1_regularization=0.01, random_state=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.l1_regularization = l1_regularization\n",
    "        self.random_state = random_state\n",
    "        self.root = None\n",
    "        self.n_classes_ = None\n",
    "        self.classes_ = None\n",
    "        self.n_features_ = None\n",
    "    \n",
    "    def _gini_impurity(self, y):\n",
    "        \"\"\"Calculate Gini impurity.\"\"\"\n",
    "        if len(y) == 0:\n",
    "            return 0.0\n",
    "        probs = np.bincount(y, minlength=self.n_classes_) / len(y)\n",
    "        return 1.0 - np.sum(probs ** 2)\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        \"\"\"Find best oblique split using logistic regression.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        if n_samples < self.min_samples_split:\n",
    "            return None, None\n",
    "        \n",
    "        # Use fast logistic regression for initial split direction\n",
    "        try:\n",
    "            lr = LogisticRegression(\n",
    "                penalty='l1', solver='liblinear', C=1.0/(self.l1_regularization + 1e-6),\n",
    "                random_state=self.random_state, max_iter=100\n",
    "            )\n",
    "            lr.fit(X, y)\n",
    "            weights = lr.coef_.ravel()\n",
    "            bias = lr.intercept_[0]\n",
    "        except:\n",
    "            return None, None\n",
    "        \n",
    "        # Refine with ISTA for sparsity\n",
    "        weights, bias = train_logistic_ista(X, y, l1_lambda=self.l1_regularization)\n",
    "        \n",
    "        # Check if split is valid\n",
    "        scores = X @ weights + bias\n",
    "        left_mask = scores < 0\n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
    "            return None, None\n",
    "        \n",
    "        return weights, bias\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        \"\"\"Recursively build the tree.\"\"\"\n",
    "        node = ObliqueNode()\n",
    "        node.n_samples = len(y)\n",
    "        \n",
    "        # Calculate class probabilities\n",
    "        class_counts = np.bincount(y, minlength=self.n_classes_)\n",
    "        node.class_probs = class_counts / len(y)\n",
    "        node.predicted_class = np.argmax(class_counts)\n",
    "        \n",
    "        # Check stopping conditions\n",
    "        if (depth >= self.max_depth or \n",
    "            len(y) < self.min_samples_split or \n",
    "            len(np.unique(y)) == 1):\n",
    "            return node\n",
    "        \n",
    "        # Find best split\n",
    "        weights, bias = self._find_best_split(X, y)\n",
    "        \n",
    "        if weights is None:\n",
    "            return node\n",
    "        \n",
    "        # Create split\n",
    "        node.is_leaf = False\n",
    "        node.weights = weights\n",
    "        node.bias = bias\n",
    "        \n",
    "        scores = X @ weights + bias\n",
    "        left_mask = scores < 0\n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        # Recursively build children\n",
    "        node.left_child = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        node.right_child = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the oblique decision tree.\"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        self.n_features_ = X.shape[1]\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        self.root = self._build_tree(X, y)\n",
    "        return self\n",
    "    \n",
    "    def _predict_single(self, x, node):\n",
    "        \"\"\"Predict class for a single sample.\"\"\"\n",
    "        if node.is_leaf:\n",
    "            return node.class_probs\n",
    "        \n",
    "        score = np.dot(x, node.weights) + node.bias\n",
    "        if score < 0:\n",
    "            return self._predict_single(x, node.left_child)\n",
    "        else:\n",
    "            return self._predict_single(x, node.right_child)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities.\"\"\"\n",
    "        X = np.asarray(X)\n",
    "        return np.array([self._predict_single(x, self.root) for x in X])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels.\"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return self.classes_[np.argmax(proba, axis=1)]\n",
    "\n",
    "print(\"âœ“ ObliqueDecisionTree class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL DEFINITIONS\n",
    "# ============================================================================\n",
    "\n",
    "models = {\n",
    "    'CART': {\n",
    "        'model': DecisionTreeClassifier(\n",
    "            criterion='gini',\n",
    "            max_depth=10,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            random_state=RANDOM_STATE\n",
    "        ),\n",
    "        'use_scaled': False,  # CART doesn't need scaling\n",
    "        'color': '#3B82F6'\n",
    "    },\n",
    "    'k-NN': {\n",
    "        'model': KNeighborsClassifier(\n",
    "            n_neighbors=5,\n",
    "            weights='distance',\n",
    "            metric='minkowski',\n",
    "            p=2\n",
    "        ),\n",
    "        'use_scaled': True,  # k-NN needs scaling\n",
    "        'color': '#10B981'\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            criterion='gini',\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'use_scaled': False,  # Random Forest doesn't need scaling\n",
    "        'color': '#F59E0B'\n",
    "    },\n",
    "    'Oblique Tree': {\n",
    "        'model': ObliqueDecisionTree(\n",
    "            max_depth=6,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            l1_regularization=0.05,\n",
    "            random_state=RANDOM_STATE\n",
    "        ),\n",
    "        'use_scaled': True,  # Oblique Tree benefits from scaling\n",
    "        'color': '#EF4444'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Models defined:\")\n",
    "for name in models:\n",
    "    print(f\"  âœ“ {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN ALL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Select appropriate data (scaled or not)\n",
    "    if config['use_scaled']:\n",
    "        X_tr, X_te = X_train_scaled.values, X_test_scaled.values\n",
    "    else:\n",
    "        X_tr, X_te = X_train.values, X_test.values\n",
    "    \n",
    "    # Train model and measure time\n",
    "    start_time = time.time()\n",
    "    model = config['model']\n",
    "    model.fit(X_tr, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predict and measure time\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_proba = model.predict_proba(X_te)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    test_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_proba': y_proba,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba) if y_proba is not None else None,\n",
    "        'train_time': train_time,\n",
    "        'test_time': test_time,\n",
    "        'color': config['color']\n",
    "    }\n",
    "    \n",
    "    print(f\"  âœ“ Accuracy: {results[name]['accuracy']:.4f}\")\n",
    "    print(f\"  âœ“ Training time: {train_time:.4f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 4: Evaluation & Comparison\n",
    "\n",
    "### 4.1 Metrics Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RESULTS TABLE\n",
    "# ============================================================================\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'Precision': [results[m]['precision'] for m in results],\n",
    "    'Recall': [results[m]['recall'] for m in results],\n",
    "    'F1-Score': [results[m]['f1'] for m in results],\n",
    "    'ROC-AUC': [results[m]['roc_auc'] for m in results],\n",
    "    'Train Time (s)': [results[m]['train_time'] for m in results],\n",
    "    'Test Time (s)': [results[m]['test_time'] for m in results]\n",
    "})\n",
    "\n",
    "# Sort by F1-Score\n",
    "metrics_df = metrics_df.sort_values('F1-Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON - PERFORMANCE METRICS\")\n",
    "print(\"=\" * 80)\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# METRICS BAR CHART\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Performance metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.2\n",
    "\n",
    "ax = axes[0]\n",
    "for i, (name, res) in enumerate(results.items()):\n",
    "    values = [res['accuracy'], res['precision'], res['recall'], res['f1']]\n",
    "    ax.bar(x + i * width, values, width, label=name, color=res['color'], alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0.7, 1.0)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Training time comparison\n",
    "ax = axes[1]\n",
    "names = list(results.keys())\n",
    "colors = [results[n]['color'] for n in names]\n",
    "train_times = [results[n]['train_time'] for n in names]\n",
    "\n",
    "bars = ax.bar(names, train_times, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax.set_ylabel('Time (seconds)', fontsize=12)\n",
    "ax.set_title('Training Time Comparison', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, time_val in zip(bars, train_times):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{time_val:.3f}s', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFUSION MATRICES\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, res) in enumerate(results.items()):\n",
    "    ax = axes[idx]\n",
    "    cm = confusion_matrix(y_test, res['y_pred'])\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'],\n",
    "                annot_kws={'size': 14})\n",
    "    \n",
    "    ax.set_title(f'{name}\\nAccuracy: {res[\"accuracy\"]:.4f}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Predicted', fontsize=11)\n",
    "    ax.set_ylabel('Actual', fontsize=11)\n",
    "\n",
    "plt.suptitle('Confusion Matrices', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ROC CURVES\n",
    "# ============================================================================\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, res in results.items():\n",
    "    if res['y_proba'] is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, res['y_proba'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color=res['color'], lw=2,\n",
    "                 label=f'{name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "# Diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1.5, alpha=0.7, label='Random (AUC = 0.5)')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DETAILED CLASSIFICATION REPORTS\n",
    "# ============================================================================\n",
    "\n",
    "for name, res in results.items():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"CLASSIFICATION REPORT: {name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(classification_report(y_test, res['y_pred'], target_names=['Ham', 'Spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 5: Advanced Analysis\n",
    "\n",
    "### 5.1 Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LEARNING CURVES\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "for idx, (name, config) in enumerate(models.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get appropriate data\n",
    "    if config['use_scaled']:\n",
    "        X_data, y_data = X_train_scaled.values, y_train\n",
    "    else:\n",
    "        X_data, y_data = X_train.values, y_train\n",
    "    \n",
    "    # Calculate learning curve\n",
    "    train_sizes_abs, train_scores, val_scores = learning_curve(\n",
    "        config['model'], X_data, y_data,\n",
    "        train_sizes=train_sizes, cv=5, scoring='accuracy',\n",
    "        n_jobs=-1, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(train_sizes_abs, train_mean, 'o-', color=results[name]['color'],\n",
    "            label='Training Score')\n",
    "    ax.fill_between(train_sizes_abs, train_mean - train_std, train_mean + train_std,\n",
    "                    alpha=0.15, color=results[name]['color'])\n",
    "    \n",
    "    ax.plot(train_sizes_abs, val_mean, 's--', color=results[name]['color'],\n",
    "            label='Cross-Validation Score', alpha=0.8)\n",
    "    ax.fill_between(train_sizes_abs, val_mean - val_std, val_mean + val_std,\n",
    "                    alpha=0.15, color=results[name]['color'])\n",
    "    \n",
    "    ax.set_xlabel('Training Set Size', fontsize=11)\n",
    "    ax.set_ylabel('Accuracy', fontsize=11)\n",
    "    ax.set_title(f'{name}', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0.75, 1.02)\n",
    "\n",
    "plt.suptitle('Learning Curves', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Feature Importance (for Tree-based Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE IMPORTANCE - CART & RANDOM FOREST\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# CART Feature Importance\n",
    "cart_model = results['CART']['model']\n",
    "cart_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': cart_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[0].barh(cart_importance['feature'], cart_importance['importance'],\n",
    "             color=results['CART']['color'], alpha=0.8)\n",
    "axes[0].set_xlabel('Importance', fontsize=11)\n",
    "axes[0].set_title('CART - Top 15 Features', fontsize=12, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "rf_model = results['Random Forest']['model']\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[1].barh(rf_importance['feature'], rf_importance['importance'],\n",
    "             color=results['Random Forest']['color'], alpha=0.8)\n",
    "axes[1].set_xlabel('Importance', fontsize=11)\n",
    "axes[1].set_title('Random Forest - Top 15 Features', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Cross-Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CROSS-VALIDATION SCORES (5-Fold)\n",
    "# ============================================================================\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_results = {}\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, config in models.items():\n",
    "    # Get appropriate data\n",
    "    if config['use_scaled']:\n",
    "        X_data = X_train_scaled.values\n",
    "    else:\n",
    "        X_data = X_train.values\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(config['model'], X_data, y_train, cv=cv, scoring='accuracy')\n",
    "    cv_results[name] = scores\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Fold scores: {scores.round(4)}\")\n",
    "    print(f\"  Mean: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CROSS-VALIDATION BOX PLOT\n",
    "# ============================================================================\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "colors = [results[name]['color'] for name in cv_df.columns]\n",
    "\n",
    "bp = cv_df.boxplot(patch_artist=True, return_type='dict')\n",
    "\n",
    "# Color the boxes\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('5-Fold Cross-Validation Accuracy Distribution', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY - SPAM CLASSIFICATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find best model for each metric\n",
    "best_accuracy = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "best_precision = max(results.items(), key=lambda x: x[1]['precision'])\n",
    "best_recall = max(results.items(), key=lambda x: x[1]['recall'])\n",
    "best_f1 = max(results.items(), key=lambda x: x[1]['f1'])\n",
    "best_auc = max(results.items(), key=lambda x: x[1]['roc_auc'] if x[1]['roc_auc'] else 0)\n",
    "\n",
    "print(f\"\\nðŸ† BEST MODELS BY METRIC:\")\n",
    "print(f\"   Best Accuracy:  {best_accuracy[0]} ({best_accuracy[1]['accuracy']:.4f})\")\n",
    "print(f\"   Best Precision: {best_precision[0]} ({best_precision[1]['precision']:.4f})\")\n",
    "print(f\"   Best Recall:    {best_recall[0]} ({best_recall[1]['recall']:.4f})\")\n",
    "print(f\"   Best F1-Score:  {best_f1[0]} ({best_f1[1]['f1']:.4f})\")\n",
    "print(f\"   Best ROC-AUC:   {best_auc[0]} ({best_auc[1]['roc_auc']:.4f})\")\n",
    "\n",
    "print(f\"\\nðŸ“Š COMPLETE RESULTS TABLE:\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY OBSERVATIONS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. All models achieve good performance (>90% accuracy) on the Spambase dataset.\n",
    "\n",
    "2. Random Forest typically performs best due to ensemble averaging, which reduces\n",
    "   overfitting and captures complex feature interactions.\n",
    "\n",
    "3. CART (Decision Tree) provides good interpretability with competitive accuracy.\n",
    "   The tree structure can be visualized to understand classification rules.\n",
    "\n",
    "4. k-NN is simple but effective, especially with proper feature scaling.\n",
    "   Performance depends heavily on the choice of k and distance metric.\n",
    "\n",
    "5. Oblique Decision Tree uses linear combinations of features for splits,\n",
    "   potentially capturing relationships that axis-aligned trees miss.\n",
    "   L1 regularization promotes sparse, interpretable splits.\n",
    "\n",
    "6. For spam detection, PRECISION is particularly important to minimize\n",
    "   false positives (legitimate emails marked as spam).\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "### Dataset\n",
    "- Hopkins, M., Reeber, E., Forman, G., & Suermondt, J. (1999). **Spambase Dataset**. UCI Machine Learning Repository. https://archive.ics.uci.edu/dataset/94/spambase\n",
    "\n",
    "### Related Research\n",
    "- Rusland, N.F., et al. (2017). A Comparative Study for Spam Classifications Using Naive Bayes and SVM. *IOP Conference Series*.\n",
    "- Int. Journal of Information Security (2023). Improving Spam Email Classification Using Ensemble Techniques.\n",
    "- Knowledge-Based Systems (2008). Content-Based Dynamic Spam Classification.\n",
    "\n",
    "### Libraries\n",
    "- Scikit-learn: https://scikit-learn.org/\n",
    "- Pandas: https://pandas.pydata.org/\n",
    "- Matplotlib: https://matplotlib.org/\n",
    "- Seaborn: https://seaborn.pydata.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
